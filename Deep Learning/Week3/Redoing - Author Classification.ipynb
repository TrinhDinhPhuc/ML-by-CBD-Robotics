{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><center><h1 style=\"font-size:40px;color:#20B2AA\">Author Classification </h1></center>\n",
    "![](https://images.blog.whsmith.co.uk/leadimage/top-books-2015-postlead.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np \n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors=[]\n",
    "titles=[]\n",
    "texts=[]\n",
    "for fol in glob.glob(\"F:\\\\data\\\\Author Classification\\\\Training\\\\*\"):\n",
    "    for index, path in enumerate(glob.glob(os.path.join(fol,\"*.txt\"))):\n",
    "        arr = path.split(\"\\\\\")\n",
    "        authors.append(arr[4])\n",
    "        titles.append(str(arr[5]).replace(\".txt\",\"\"))\n",
    "        with open(path, encoding=\"utf8\", errors='ignore') as myfile:\n",
    "            texts.append(myfile.read().rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for index, value in enumerate(texts):\n",
    "    texts[index] = re.sub(r'[^\\w]', ' ',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ABBOTT','JACOB','ABBOTT','JOHN','ALLEN ','GRANT','ALTSHELER','JOSEPH','APPLETON','VICTOR','HORATIO','ALGER','TIMOTHY','SHAY','Abbott','Jacob','Abbott','John','Allen ','Grant','Altsheler','Joseph','Appleton','Victor','Horatio','Alger','Timothy','Shay','abbott','jacob','abbott','john','allen ','grant','altsheler','joseph','appleton','victor','horatio','alger','timothy','shay','PROJECT GUTENBERG EBOOK','GUTENBERG EBOOK','GUTENBERG','the Project Gutenberg Online Distributed Proofreading Team','www gutenberg org','www pgdp net','THE PROJECT EBOOK','THIS PROJECT EBOOK','www gutenberg org','THIS PROJECT  EBOOK','THE PROJECT  EBOOK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in enumerate(texts):\n",
    "    try:\n",
    "        texts[index] = str(texts[index]).split(\"START OF\")[1]\n",
    "        texts[index] =\" \".join(texts[index].split())\n",
    "    except IndexError:\n",
    "        pass\n",
    "    for i in value.split():\n",
    "        if i in (names):\n",
    "            texts[index]= str(texts[index]).replace(i,\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'author':authors,'title':titles})\n",
    "data['text'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.replace('\\r', '')\n",
    "data['text'] = data['text'].str.replace('\\n', '')\n",
    "data['text'] = data['text'].str.replace(\"\\'s\", '')\n",
    "data['text'] = data['text'].str.replace(\"\\'s\", '')\n",
    "data['text'] = data['text'].str.replace(\"\\'\", '')\n",
    "data['text'] = data['text'].str.replace(\"'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape(171, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Alexander the Great</td>\n",
       "      <td>THE PROJECT  EBOOK ALEXANDER THE GREAT E text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>THIS PROJECT  EBOOK BRUNO Produced by Suzanne ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Caleb in the Country</td>\n",
       "      <td>THE PROJECT  EBOOK CALEB IN THE COUNTRY E text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Charles I</td>\n",
       "      <td>THIS PROJECT  EBOOK CHARLES I Produced by D Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>THE PROJECT  EBOOK CLEOPATRA E text prepared b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                 title  \\\n",
       "0  Abbott Jacob   Alexander the Great   \n",
       "1  Abbott Jacob                 Bruno   \n",
       "2  Abbott Jacob  Caleb in the Country   \n",
       "3  Abbott Jacob             Charles I   \n",
       "4  Abbott Jacob             Cleopatra   \n",
       "\n",
       "                                                text  \n",
       "0  THE PROJECT  EBOOK ALEXANDER THE GREAT E text ...  \n",
       "1  THIS PROJECT  EBOOK BRUNO Produced by Suzanne ...  \n",
       "2  THE PROJECT  EBOOK CALEB IN THE COUNTRY E text...  \n",
       "3  THIS PROJECT  EBOOK CHARLES I Produced by D Al...  \n",
       "4  THE PROJECT  EBOOK CLEOPATRA E text prepared b...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"data shape{0}\".format(data.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors1=[]\n",
    "titles1=[]\n",
    "texts1=[]\n",
    "for fol in glob.glob(\"F:\\\\data\\\\Author Classification\\\\Testing\\\\*\"):\n",
    "    for index, path in enumerate(glob.glob(os.path.join(fol,\"*.txt\"))):\n",
    "        arr = path.split(\"\\\\\")\n",
    "        authors1.append(arr[4])\n",
    "        titles1.append(str(arr[5]).replace(\".txt\",\"\"))\n",
    "        with open(path, encoding=\"utf8\", errors='ignore') as myfile:\n",
    "            texts1.append(myfile.read().rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for index, value in enumerate(texts1):\n",
    "    texts1[index] = re.sub(r'[^\\w]', ' ',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ABBOTT','JACOB','ABBOTT','JOHN','ALLEN ','GRANT','ALTSHELER','JOSEPH','APPLETON','VICTOR','HORATIO','ALGER','TIMOTHY','SHAY','Abbott','Jacob','Abbott','John','Allen ','Grant','Altsheler','Joseph','Appleton','Victor','Horatio','Alger','Timothy','Shay','abbott','jacob','abbott','john','allen ','grant','altsheler','joseph','appleton','victor','horatio','alger','timothy','shay','PROJECT GUTENBERG EBOOK','GUTENBERG EBOOK','GUTENBERG','the Project Gutenberg Online Distributed Proofreading Team','www gutenberg org','www pgdp net','THE PROJECT EBOOK','THIS PROJECT EBOOK','www gutenberg org','THIS PROJECT  EBOOK','THE PROJECT  EBOOK']\n",
    "for index, value in enumerate(texts1):\n",
    "    try:\n",
    "        texts1[index] = str(texts1[index]).split(\"START OF\")[1]\n",
    "        texts1[index] =\" \".join(texts1[index].split())\n",
    "    except IndexError:\n",
    "        pass\n",
    "    for i in value.split():\n",
    "        if i in (names):\n",
    "            texts1[index]= str(texts1[index]).replace(i,\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape(71, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Jonas on a Farm in Winter</td>\n",
       "      <td>THE PROJECT  EBOOK JONAS ON A FARM IN WINTER E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>King Alfred of England</td>\n",
       "      <td>THIS PROJECT  EBOOK KING ALFRED OF ENGLAND Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Marco Paul's Voyages and Travels; Vermont</td>\n",
       "      <td>THE PROJECT  EBOOK MARCO PAUL S VOYAGES AND TR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Margaret of Anjou</td>\n",
       "      <td>THIS PROJECT  EBOOK MARGARET OF ANJOU Produced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbott Jacob</td>\n",
       "      <td>Mary Erskine</td>\n",
       "      <td>THIS PROJECT  EBOOK MARY ERSKINE Produced by S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                      title  \\\n",
       "0  Abbott Jacob                  Jonas on a Farm in Winter   \n",
       "1  Abbott Jacob                     King Alfred of England   \n",
       "2  Abbott Jacob  Marco Paul's Voyages and Travels; Vermont   \n",
       "3  Abbott Jacob                          Margaret of Anjou   \n",
       "4  Abbott Jacob                               Mary Erskine   \n",
       "\n",
       "                                                text  \n",
       "0  THE PROJECT  EBOOK JONAS ON A FARM IN WINTER E...  \n",
       "1  THIS PROJECT  EBOOK KING ALFRED OF ENGLAND Pro...  \n",
       "2  THE PROJECT  EBOOK MARCO PAUL S VOYAGES AND TR...  \n",
       "3  THIS PROJECT  EBOOK MARGARET OF ANJOU Produced...  \n",
       "4  THIS PROJECT  EBOOK MARY ERSKINE Produced by S...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.DataFrame({'author':authors1,'title':titles1})\n",
    "data_test['text'] = texts1\n",
    "data_test['text'] = data_test['text'].str.replace('\\r', '')\n",
    "data_test['text'] = data_test['text'].str.replace('\\n', '')\n",
    "data_test['text'] = data_test['text'].str.replace(\"\\'s\", '')\n",
    "data_test['text'] = data_test['text'].str.replace(\"\\'s\", '')\n",
    "data_test['text'] = data_test['text'].str.replace(\"\\'\", '')\n",
    "data_test['text'] = data_test['text'].str.replace(\"'\", '')\n",
    "print(\"data shape{0}\".format(data_test.shape))\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.text.tolist()\n",
    "y = data.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           34,
           32,
           22,
           22,
           22,
           21,
           18
          ],
          "colorscale": "Jet"
         },
         "type": "bar",
         "x": [
          "Abbott Jacob",
          "Abbott John",
          "Allen Grant",
          "Altsheler Joseph",
          "Appleton Victor",
          "Horatio Alger",
          "Timothy Shay"
         ],
         "y": [
          34,
          32,
          22,
          22,
          22,
          21,
          18
         ]
        }
       ],
       "layout": {
        "title": "Số lượng đầu sách của mỗi tác giả"
       }
      },
      "text/html": [
       "<div id=\"282cfd93-947c-4232-8643-0157955883ee\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"282cfd93-947c-4232-8643-0157955883ee\", [{\"type\": \"bar\", \"x\": [\"Abbott Jacob\", \"Abbott John\", \"Allen Grant\", \"Altsheler Joseph\", \"Appleton Victor\", \"Horatio Alger\", \"Timothy Shay\"], \"y\": [34, 32, 22, 22, 22, 21, 18], \"marker\": {\"colorscale\": \"Jet\", \"color\": [34, 32, 22, 22, 22, 21, 18]}}], {\"title\": \"S\\u1ed1 l\\u01b0\\u1ee3ng \\u0111\\u1ea7u s\\u00e1ch c\\u1ee7a m\\u1ed7i t\\u00e1c gi\\u1ea3\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"282cfd93-947c-4232-8643-0157955883ee\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"282cfd93-947c-4232-8643-0157955883ee\", [{\"type\": \"bar\", \"x\": [\"Abbott Jacob\", \"Abbott John\", \"Allen Grant\", \"Altsheler Joseph\", \"Appleton Victor\", \"Horatio Alger\", \"Timothy Shay\"], \"y\": [34, 32, 22, 22, 22, 21, 18], \"marker\": {\"colorscale\": \"Jet\", \"color\": [34, 32, 22, 22, 22, 21, 18]}}], {\"title\": \"S\\u1ed1 l\\u01b0\\u1ee3ng \\u0111\\u1ea7u s\\u00e1ch c\\u1ee7a m\\u1ed7i t\\u00e1c gi\\u1ea3\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "data = [go.Bar(\n",
    "            x = y.unique(),\n",
    "            y = y.value_counts().values,\n",
    "            marker= dict(colorscale='Jet',\n",
    "                         color = y.value_counts().values))]\n",
    "layout = go.Layout(  title='Số lượng đầu sách của mỗi tác giả')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='basic-bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://image.ibb.co/iN4YMy/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set = data_test.text.tolist()\n",
    "y_test_set = data_test.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           13,
           12,
           10,
           10,
           10,
           10,
           6
          ],
          "colorscale": "Jet"
         },
         "type": "bar",
         "x": [
          "Abbott Jacob",
          "Abbott John",
          "Allen Grant",
          "Altsheler Joseph",
          "Appleton Victor",
          "Horatio Alger",
          "Timothy Shay"
         ],
         "y": [
          13,
          12,
          10,
          10,
          10,
          10,
          6
         ]
        }
       ],
       "layout": {
        "title": "Số lượng đầu sách của mỗi tác giả"
       }
      },
      "text/html": [
       "<div id=\"391f7eff-ddac-48e0-b0e8-d2299cde6176\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"391f7eff-ddac-48e0-b0e8-d2299cde6176\", [{\"type\": \"bar\", \"x\": [\"Abbott Jacob\", \"Abbott John\", \"Allen Grant\", \"Altsheler Joseph\", \"Appleton Victor\", \"Horatio Alger\", \"Timothy Shay\"], \"y\": [13, 12, 10, 10, 10, 10, 6], \"marker\": {\"colorscale\": \"Jet\", \"color\": [13, 12, 10, 10, 10, 10, 6]}}], {\"title\": \"S\\u1ed1 l\\u01b0\\u1ee3ng \\u0111\\u1ea7u s\\u00e1ch c\\u1ee7a m\\u1ed7i t\\u00e1c gi\\u1ea3\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"391f7eff-ddac-48e0-b0e8-d2299cde6176\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"391f7eff-ddac-48e0-b0e8-d2299cde6176\", [{\"type\": \"bar\", \"x\": [\"Abbott Jacob\", \"Abbott John\", \"Allen Grant\", \"Altsheler Joseph\", \"Appleton Victor\", \"Horatio Alger\", \"Timothy Shay\"], \"y\": [13, 12, 10, 10, 10, 10, 6], \"marker\": {\"colorscale\": \"Jet\", \"color\": [13, 12, 10, 10, 10, 10, 6]}}], {\"title\": \"S\\u1ed1 l\\u01b0\\u1ee3ng \\u0111\\u1ea7u s\\u00e1ch c\\u1ee7a m\\u1ed7i t\\u00e1c gi\\u1ea3\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "data1= [go.Bar(\n",
    "            x = y_test_set.unique(),\n",
    "            y = y_test_set.value_counts().values,\n",
    "            marker= dict(colorscale='Jet',\n",
    "                         color = y_test_set.value_counts().values))]\n",
    "layout = go.Layout(  title='Số lượng đầu sách của mỗi tác giả')\n",
    "fig = go.Figure(data=data1, layout=layout)\n",
    "py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://image.ibb.co/kH3hEJ/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_test.text, data_test.author, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape: (56,)(56,)\n",
      "testing shape : (15,)(15,)\n"
     ]
    }
   ],
   "source": [
    "print(\"training shape: {}{}\".format(X_train.shape,y_train.shape))\n",
    "print(\"testing shape : {}{}\".format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_train = tfidf_vector.fit_transform(X_train).toarray()\n",
    "tfidf_test = tfidf_vector.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (56, 48415)(15, 48415)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shape: {}{}\".format(tfidf_train.shape,tfidf_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Abbott Jacob       1.00      1.00      1.00         2\n",
      "     Abbott John       1.00      1.00      1.00         1\n",
      "     Allen Grant       1.00      1.00      1.00         2\n",
      "Altsheler Joseph       1.00      1.00      1.00         1\n",
      " Appleton Victor       1.00      1.00      1.00         4\n",
      "   Horatio Alger       0.60      1.00      0.75         3\n",
      "    Timothy Shay       0.00      0.00      0.00         2\n",
      "\n",
      "     avg / total       0.79      0.87      0.82        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators=100, random_state=888)\n",
    "rfc_model.fit(tfidf_train,y_train)\n",
    "pr = rfc_model.predict(tfidf_test)\n",
    "print(classification_report(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Abbott Jacob       0.00      0.00      0.00         2\n",
      "     Abbott John       0.50      1.00      0.67         1\n",
      "     Allen Grant       0.50      1.00      0.67         2\n",
      "Altsheler Joseph       1.00      1.00      1.00         1\n",
      " Appleton Victor       1.00      1.00      1.00         4\n",
      "   Horatio Alger       0.67      0.67      0.67         3\n",
      "    Timothy Shay       0.00      0.00      0.00         2\n",
      "\n",
      "     avg / total       0.57      0.67      0.60        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "pr = gnb.fit(tfidf_train, y_train)\n",
    "pr = gnb.predict(tfidf_test)\n",
    "print(classification_report(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X=LabelEncoder()\n",
    "y_trainenc = labelencoder_X.fit_transform(y_train)\n",
    "y_testenc=labelencoder_X.transform(y_test)\n",
    "from keras import utils as np_utils\n",
    "y_train1h = np_utils.to_categorical(y_trainenc, 15)\n",
    "y_test1h = np_utils.to_categorical(y_testenc, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "# model imports\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# hyperparameter training imports\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.7088 - acc: 0.0000e+00 - val_loss: 2.5956 - val_acc: 0.1333\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5673 - acc: 0.2143 - val_loss: 2.0524 - val_acc: 0.1333\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8898 - acc: 0.3571 - val_loss: 1.9425 - val_acc: 0.2000\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.7276 - acc: 0.4464 - val_loss: 1.8340 - val_acc: 0.1333\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5928 - acc: 0.3214 - val_loss: 1.7523 - val_acc: 0.2667\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4063 - acc: 0.4643 - val_loss: 1.3166 - val_acc: 0.6000\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.8870 - acc: 0.8214 - val_loss: 0.7031 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.4642 - acc: 1.0000 - val_loss: 0.6703 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.2994 - acc: 0.8750 - val_loss: 1.3508 - val_acc: 0.6667\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.9676 - acc: 0.8214 - val_loss: 0.8210 - val_acc: 0.7333\n",
      "Test loss: 0.8210058212280273\n",
      "Test accuracy: 0.7333333492279053\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(Dense(512, activation='relu', input_dim=tfidf_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer = keras.optimizers.RMSprop(),\n",
    "             metrics=['accuracy'])\n",
    "model.fit(tfidf_train, y_train1h,\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=(tfidf_test, y_test1h))\n",
    "score = model.evaluate(tfidf_test, y_test1h, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.33      1.00      0.50         1\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         4\n",
      "          5       0.60      1.00      0.75         3\n",
      "          6       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.61      0.73      0.65        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_predict = model.predict_classes(tfidf_test, batch_size = None)\n",
    "print(classification_report(y_testenc, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BagofWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 51710)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(data_test.text)\n",
    "X_train_counts = count_vect.transform(X_train)\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Abbott Jacob       1.00      1.00      1.00         2\n",
      "     Abbott John       1.00      1.00      1.00         1\n",
      "     Allen Grant       1.00      0.50      0.67         2\n",
      "Altsheler Joseph       1.00      1.00      1.00         1\n",
      " Appleton Victor       0.80      1.00      0.89         4\n",
      "   Horatio Alger       0.75      1.00      0.86         3\n",
      "    Timothy Shay       1.00      0.50      0.67         2\n",
      "\n",
      "     avg / total       0.90      0.87      0.85        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_model2 = RandomForestClassifier(n_estimators=100, random_state=888)\n",
    "rfc_model2.fit(X_train_counts,y_train)\n",
    "pr = rfc_model2.predict(X_test_counts)\n",
    "print(classification_report(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Abbott Jacob       0.00      0.00      0.00         2\n",
      "     Abbott John       0.50      1.00      0.67         1\n",
      "     Allen Grant       0.67      1.00      0.80         2\n",
      "Altsheler Joseph       1.00      1.00      1.00         1\n",
      " Appleton Victor       1.00      1.00      1.00         4\n",
      "   Horatio Alger       0.67      0.67      0.67         3\n",
      "    Timothy Shay       0.50      0.50      0.50         2\n",
      "\n",
      "     avg / total       0.66      0.73      0.68        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "pr = gnb.fit(X_train_counts.toarray(), y_train)\n",
    "pr = gnb.predict(X_test_counts.toarray())\n",
    "print(classification_report(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.7198 - acc: 0.1607 - val_loss: 5.0536 - val_acc: 0.1333\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 4.6910 - acc: 0.1964 - val_loss: 7.2425 - val_acc: 0.0667\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 6.4603 - acc: 0.1607 - val_loss: 4.7564 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 6.4198 - acc: 0.3571 - val_loss: 6.2813 - val_acc: 0.3333\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 7.5987 - acc: 0.4464 - val_loss: 3.8751 - val_acc: 0.4667\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 5.8690 - acc: 0.4464 - val_loss: 2.6860 - val_acc: 0.6667\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 4.5634 - acc: 0.6786 - val_loss: 1.4329 - val_acc: 0.6667\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.9300 - acc: 0.6786 - val_loss: 1.4928 - val_acc: 0.4667\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3112 - acc: 0.8571 - val_loss: 1.0796 - val_acc: 0.7333\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2176 - acc: 0.8571 - val_loss: 1.1237 - val_acc: 0.7333\n",
      "Test loss: 1.1237043142318726\n",
      "Test accuracy: 0.7333333492279053\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         2\n",
      "          1       0.33      1.00      0.50         1\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.50      1.00      0.67         1\n",
      "          4       1.00      1.00      1.00         4\n",
      "          5       0.75      1.00      0.86         3\n",
      "          6       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.61      0.73      0.65        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_counts.toarray())\n",
    "X_train_counts_scale = scaler.transform(X_train_counts.toarray())\n",
    "X_test_counts_scale = scaler.transform(X_test_counts.toarray())\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(Dense(512, activation='relu', input_dim=X_train_counts_scale.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer = keras.optimizers.RMSprop(),\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train_counts_scale, y_train1h,\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test_counts_scale, y_test1h))\n",
    "score = model.evaluate(X_test_counts_scale, y_test1h, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "classes = model.predict_classes(X_test_counts_scale, batch_size = None)\n",
    "print(classification_report(y_testenc, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
