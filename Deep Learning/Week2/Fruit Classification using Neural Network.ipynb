{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Fruit Classification using Neural Network</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import keras\n",
    "import numpy as np \n",
    "from keras.datasets.cifar10 import load_data\n",
    "import glob\n",
    "import os\n",
    "import keras \n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_images = []\n",
    "labels = []\n",
    "for fruit_dir_path in glob.glob(\"F:/data/fruits-360/Training/*\"):\n",
    "    fruit_label = fruit_dir_path.split(\"/\") #['F:', 'data', 'fruits-360', 'Training\\\\Apple Braeburn']\n",
    "    fruit_label = fruit_label[3]\n",
    "    for image_path in glob.glob(os.path.join(fruit_dir_path,\"*.jpg\")): #['F:/data/fruits-360/Training\\\\Apple Braeburn\\\\0_100.jpg', 'F:/data/fruits-360/Training\\\\Apple Braeburn\\\\100_100.jpg',\n",
    "        image = cv2.imread(image_path,cv2.IMREAD_COLOR) # cv2.imread() to read an image\n",
    "        image = cv2.resize(image,(45,45)) # Loads a color image\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR) # conver RGB to BGR \n",
    "        fruit_images.append(image)\n",
    "        labels.append(fruit_label)\n",
    "fruit_images_ARR = np.array(fruit_images)\n",
    "labels_ARR = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[254, 255, 255],\n",
       "        [254, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 253, 254],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[254, 255, 255],\n",
       "        [254, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [254, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[252, 255, 251],\n",
       "        [255, 253, 254],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35625"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fruit_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35625"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 45)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fruit_images[0]),len(fruit_images_ARR[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_images[0].all()==fruit_images_ARR[0].all() is True #just to check whether or not there is a different between list and array here =))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Training\\\\Apple Braeburn', 'Training\\\\Apple Braeburn',\n",
       "       'Training\\\\Apple Braeburn', ..., 'Training\\\\Tangelo',\n",
       "       'Training\\\\Tangelo', 'Training\\\\Tangelo'], dtype='<U28')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_Dict = {key:value for value,key in enumerate(np.unique(labels_ARR))} #add index 0,1,2... to be keys of the values\n",
    "id_label_Dict = {key:value for value,key in label_id_Dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Training\\\\Apple Braeburn',\n",
       " 1: 'Training\\\\Apple Golden 1',\n",
       " 2: 'Training\\\\Apple Golden 2',\n",
       " 3: 'Training\\\\Apple Golden 3',\n",
       " 4: 'Training\\\\Apple Granny Smith',\n",
       " 5: 'Training\\\\Apple Red 1',\n",
       " 6: 'Training\\\\Apple Red 2',\n",
       " 7: 'Training\\\\Apple Red 3',\n",
       " 8: 'Training\\\\Apple Red Delicious',\n",
       " 9: 'Training\\\\Apple Red Yellow',\n",
       " 10: 'Training\\\\Apricot',\n",
       " 11: 'Training\\\\Avocado',\n",
       " 12: 'Training\\\\Avocado ripe',\n",
       " 13: 'Training\\\\Banana',\n",
       " 14: 'Training\\\\Banana Red',\n",
       " 15: 'Training\\\\Cactus fruit',\n",
       " 16: 'Training\\\\Cantaloupe 1',\n",
       " 17: 'Training\\\\Cantaloupe 2',\n",
       " 18: 'Training\\\\Carambula',\n",
       " 19: 'Training\\\\Cherry 1',\n",
       " 20: 'Training\\\\Cherry 2',\n",
       " 21: 'Training\\\\Cherry Rainier',\n",
       " 22: 'Training\\\\Clementine',\n",
       " 23: 'Training\\\\Cocos',\n",
       " 24: 'Training\\\\Dates',\n",
       " 25: 'Training\\\\Granadilla',\n",
       " 26: 'Training\\\\Grape Pink',\n",
       " 27: 'Training\\\\Grape White',\n",
       " 28: 'Training\\\\Grape White 2',\n",
       " 29: 'Training\\\\Grapefruit Pink',\n",
       " 30: 'Training\\\\Grapefruit White',\n",
       " 31: 'Training\\\\Guava',\n",
       " 32: 'Training\\\\Huckleberry',\n",
       " 33: 'Training\\\\Kaki',\n",
       " 34: 'Training\\\\Kiwi',\n",
       " 35: 'Training\\\\Kumquats',\n",
       " 36: 'Training\\\\Lemon',\n",
       " 37: 'Training\\\\Lemon Meyer',\n",
       " 38: 'Training\\\\Limes',\n",
       " 39: 'Training\\\\Lychee',\n",
       " 40: 'Training\\\\Mandarine',\n",
       " 41: 'Training\\\\Mango',\n",
       " 42: 'Training\\\\Maracuja',\n",
       " 43: 'Training\\\\Melon Piel de Sapo',\n",
       " 44: 'Training\\\\Mulberry',\n",
       " 45: 'Training\\\\Nectarine',\n",
       " 46: 'Training\\\\Orange',\n",
       " 47: 'Training\\\\Papaya',\n",
       " 48: 'Training\\\\Passion Fruit',\n",
       " 49: 'Training\\\\Peach',\n",
       " 50: 'Training\\\\Peach Flat',\n",
       " 51: 'Training\\\\Pear',\n",
       " 52: 'Training\\\\Pear Abate',\n",
       " 53: 'Training\\\\Pear Monster',\n",
       " 54: 'Training\\\\Pear Williams',\n",
       " 55: 'Training\\\\Pepino',\n",
       " 56: 'Training\\\\Physalis',\n",
       " 57: 'Training\\\\Physalis with Husk',\n",
       " 58: 'Training\\\\Pineapple',\n",
       " 59: 'Training\\\\Pineapple Mini',\n",
       " 60: 'Training\\\\Pitahaya Red',\n",
       " 61: 'Training\\\\Plum',\n",
       " 62: 'Training\\\\Pomegranate',\n",
       " 63: 'Training\\\\Quince',\n",
       " 64: 'Training\\\\Rambutan',\n",
       " 65: 'Training\\\\Raspberry',\n",
       " 66: 'Training\\\\Salak',\n",
       " 67: 'Training\\\\Strawberry',\n",
       " 68: 'Training\\\\Strawberry Wedge',\n",
       " 69: 'Training\\\\Tamarillo',\n",
       " 70: 'Training\\\\Tangelo'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_label_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training\\\\Apple Braeburn': 0,\n",
       " 'Training\\\\Apple Golden 1': 1,\n",
       " 'Training\\\\Apple Golden 2': 2,\n",
       " 'Training\\\\Apple Golden 3': 3,\n",
       " 'Training\\\\Apple Granny Smith': 4,\n",
       " 'Training\\\\Apple Red 1': 5,\n",
       " 'Training\\\\Apple Red 2': 6,\n",
       " 'Training\\\\Apple Red 3': 7,\n",
       " 'Training\\\\Apple Red Delicious': 8,\n",
       " 'Training\\\\Apple Red Yellow': 9,\n",
       " 'Training\\\\Apricot': 10,\n",
       " 'Training\\\\Avocado': 11,\n",
       " 'Training\\\\Avocado ripe': 12,\n",
       " 'Training\\\\Banana': 13,\n",
       " 'Training\\\\Banana Red': 14,\n",
       " 'Training\\\\Cactus fruit': 15,\n",
       " 'Training\\\\Cantaloupe 1': 16,\n",
       " 'Training\\\\Cantaloupe 2': 17,\n",
       " 'Training\\\\Carambula': 18,\n",
       " 'Training\\\\Cherry 1': 19,\n",
       " 'Training\\\\Cherry 2': 20,\n",
       " 'Training\\\\Cherry Rainier': 21,\n",
       " 'Training\\\\Clementine': 22,\n",
       " 'Training\\\\Cocos': 23,\n",
       " 'Training\\\\Dates': 24,\n",
       " 'Training\\\\Granadilla': 25,\n",
       " 'Training\\\\Grape Pink': 26,\n",
       " 'Training\\\\Grape White': 27,\n",
       " 'Training\\\\Grape White 2': 28,\n",
       " 'Training\\\\Grapefruit Pink': 29,\n",
       " 'Training\\\\Grapefruit White': 30,\n",
       " 'Training\\\\Guava': 31,\n",
       " 'Training\\\\Huckleberry': 32,\n",
       " 'Training\\\\Kaki': 33,\n",
       " 'Training\\\\Kiwi': 34,\n",
       " 'Training\\\\Kumquats': 35,\n",
       " 'Training\\\\Lemon': 36,\n",
       " 'Training\\\\Lemon Meyer': 37,\n",
       " 'Training\\\\Limes': 38,\n",
       " 'Training\\\\Lychee': 39,\n",
       " 'Training\\\\Mandarine': 40,\n",
       " 'Training\\\\Mango': 41,\n",
       " 'Training\\\\Maracuja': 42,\n",
       " 'Training\\\\Melon Piel de Sapo': 43,\n",
       " 'Training\\\\Mulberry': 44,\n",
       " 'Training\\\\Nectarine': 45,\n",
       " 'Training\\\\Orange': 46,\n",
       " 'Training\\\\Papaya': 47,\n",
       " 'Training\\\\Passion Fruit': 48,\n",
       " 'Training\\\\Peach': 49,\n",
       " 'Training\\\\Peach Flat': 50,\n",
       " 'Training\\\\Pear': 51,\n",
       " 'Training\\\\Pear Abate': 52,\n",
       " 'Training\\\\Pear Monster': 53,\n",
       " 'Training\\\\Pear Williams': 54,\n",
       " 'Training\\\\Pepino': 55,\n",
       " 'Training\\\\Physalis': 56,\n",
       " 'Training\\\\Physalis with Husk': 57,\n",
       " 'Training\\\\Pineapple': 58,\n",
       " 'Training\\\\Pineapple Mini': 59,\n",
       " 'Training\\\\Pitahaya Red': 60,\n",
       " 'Training\\\\Plum': 61,\n",
       " 'Training\\\\Pomegranate': 62,\n",
       " 'Training\\\\Quince': 63,\n",
       " 'Training\\\\Rambutan': 64,\n",
       " 'Training\\\\Raspberry': 65,\n",
       " 'Training\\\\Salak': 66,\n",
       " 'Training\\\\Strawberry': 67,\n",
       " 'Training\\\\Strawberry Wedge': 68,\n",
       " 'Training\\\\Tamarillo': 69,\n",
       " 'Training\\\\Tangelo': 70}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_id_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = np.array([label_id_Dict[x] for x in labels_ARR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 70, 70, 70])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35625, 45, 45, 3), (35625,), (35625,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_images_ARR.shape, label_ids.shape, labels_ARR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_fruit_images = []\n",
    "validation_labels = [] \n",
    "for fruit_dir_path in glob.glob(\"F:/data/fruits-360/Training/*\"):\n",
    "    fruit_label = fruit_dir_path.split(\"/\")[-1]\n",
    "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        validation_fruit_images.append(image)\n",
    "        validation_labels.append(fruit_label)\n",
    "validation_fruit_images = np.array(validation_fruit_images)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_label_ids = np.array([label_id_Dict[x] for x in validation_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 70, 70, 70])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35625, 45, 45, 3), (35625,))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_fruit_images.shape, validation_label_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = fruit_images_ARR, validation_fruit_images\n",
    "Y_train, Y_test = label_ids, validation_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.99607843, 1.        , 1.        ],\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 0.99215686, 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.99607843, 1.        , 1.        ],\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.98823529, 1.        , 0.98431373],\n",
       "         [1.        , 0.99215686, 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.99215686, 1.        , 0.98823529],\n",
       "         [1.        , 0.98823529, 0.99607843],\n",
       "         [1.        , 0.99607843, 1.        ],\n",
       "         ...,\n",
       "         [1.        , 0.99215686, 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.97647059, 1.        , 0.99215686],\n",
       "         [1.        , 0.98823529, 1.        ],\n",
       "         [1.        , 0.98823529, 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.98039216, 1.        , 1.        ],\n",
       "         [1.        , 0.99215686, 1.        ],\n",
       "         [1.        , 0.99607843, 1.        ],\n",
       "         ...,\n",
       "         [0.98823529, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 0.99215686, 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.98823529, 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.99215686, 1.        , 0.98431373],\n",
       "         [1.        , 0.98823529, 0.99607843],\n",
       "         [1.        , 0.99215686, 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.97647059, 1.        , 0.99215686],\n",
       "         [1.        , 0.98823529, 1.        ],\n",
       "         [1.        , 0.98823529, 1.        ],\n",
       "         ...,\n",
       "         [0.98039216, 1.        , 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.98039216, 0.99607843, 1.        ],\n",
       "         [1.        , 0.98823529, 1.        ],\n",
       "         [1.        , 0.99215686, 0.99607843],\n",
       "         ...,\n",
       "         [0.98039216, 1.        , 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 0.99215686, 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.98823529, 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 0.99607843, 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 0.99215686],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 0.99215686],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 0.99607843, 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 0.98823529],\n",
       "         [1.        , 1.        , 0.99607843],\n",
       "         [1.        , 0.99607843, 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 0.99607843, 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.98823529, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.98823529, 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize color values to between 0 and 1\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.99607843, 1.        , 1.        ],\n",
       "        [0.99607843, 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [1.        , 0.99215686, 0.99607843],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]],\n",
       "\n",
       "       [[0.99607843, 1.        , 1.        ],\n",
       "        [0.99607843, 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [0.99607843, 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.98823529, 1.        , 0.98431373],\n",
       "        [1.        , 0.99215686, 0.99607843],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35625, 45, 45, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6075"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45*45*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a flattened version for some of our models\n",
    "X_flat_train = X_train.reshape(X_train.shape[0], 45*45*3)\n",
    "X_flat_test = X_test.reshape(X_test.shape[0], 45*45*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99607843, 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35625,), (35625,))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ids.shape, validation_label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35625,), (35625,))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (BEFORE encode): (4,)\n",
      "Shape of data (AFTER  encode): (4, 9)\n",
      "\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "index: 0\n",
      "encoded datum: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "decoded datum: 1\n",
      "\n",
      "index: 1\n",
      "encoded datum: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "decoded datum: 5\n",
      "\n",
      "index: 2\n",
      "encoded datum: [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "decoded datum: 3\n",
      "\n",
      "index: 3\n",
      "encoded datum: [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "decoded datum: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.array([1, 5, 3, 8])\n",
    "def encode(data):\n",
    "    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n",
    "    encoded = to_categorical(data)\n",
    "    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n",
    "    return encoded\n",
    "encoded_data = encode(data)\n",
    "print(encoded_data)\n",
    "def decode(datum):\n",
    "    return np.argmax(datum)\n",
    "for i in range(encoded_data.shape[0]):\n",
    "    datum = encoded_data[i]\n",
    "    print('index: %d' % i)\n",
    "    print('encoded datum: %s' % datum)\n",
    "    decoded_datum = decode(encoded_data[i])\n",
    "    print('decoded datum: %s' % decoded_datum)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sizes: (35625, 45, 45, 3) (35625, 45, 45, 3) (35625, 71) (35625, 71)\n",
      "Flattened: (35625, 6075) (35625, 6075)\n"
     ]
    }
   ],
   "source": [
    "#One Hot Encode the Output\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "print('Original Sizes:', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "print('Flattened:', X_flat_train.shape, X_flat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 45, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train[13000].shape)\n",
    "plt.imshow(X_train[13000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Our Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "\n",
    "# Import the backend\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A basic model (2 dense layers (256-128 nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 71)                9159      \n",
      "=================================================================\n",
      "Total params: 1,597,511\n",
      "Trainable params: 1,597,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense = Sequential()\n",
    "\n",
    "# Add dense layers to create a fully connected MLP\n",
    "# Note that we specify an input shape for the first layer, but only the first layer.\n",
    "# Relu is the activation function used\n",
    "model_dense.add(Dense(256, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "# Dropout layers remove features and fight overfitting\n",
    "model_dense.add(Dropout(0.1))\n",
    "model_dense.add(Dense(128, activation='relu'))\n",
    "model_dense.add(Dropout(0.1))\n",
    "# End with a number of units equal to the number of classes we have for our outcome\n",
    "model_dense.add(Dense(71, activation='softmax'))\n",
    "\n",
    "model_dense.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_dense.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35625 samples, validate on 35625 samples\n",
      "Epoch 1/10\n",
      "35625/35625 [==============================] - 604s 17ms/step - loss: 2.9655 - acc: 0.2404 - val_loss: 1.3148 - val_acc: 0.6233\n",
      "Epoch 2/10\n",
      "35625/35625 [==============================] - 29s 822us/step - loss: 1.3641 - acc: 0.5610 - val_loss: 0.6677 - val_acc: 0.7901\n",
      "Epoch 3/10\n",
      "35625/35625 [==============================] - 28s 784us/step - loss: 0.9483 - acc: 0.6878 - val_loss: 0.4354 - val_acc: 0.8712\n",
      "Epoch 4/10\n",
      "35625/35625 [==============================] - 28s 798us/step - loss: 0.7381 - acc: 0.7543 - val_loss: 0.4527 - val_acc: 0.8431\n",
      "Epoch 5/10\n",
      "35625/35625 [==============================] - 29s 810us/step - loss: 0.6032 - acc: 0.8020 - val_loss: 0.4014 - val_acc: 0.8644\n",
      "Epoch 6/10\n",
      "35625/35625 [==============================] - 28s 778us/step - loss: 0.5184 - acc: 0.8285 - val_loss: 0.2030 - val_acc: 0.9407\n",
      "Epoch 7/10\n",
      "35625/35625 [==============================] - 28s 780us/step - loss: 0.4498 - acc: 0.8505 - val_loss: 0.1345 - val_acc: 0.9650\n",
      "Epoch 8/10\n",
      "35625/35625 [==============================] - 29s 807us/step - loss: 0.3922 - acc: 0.8696 - val_loss: 0.2034 - val_acc: 0.9287\n",
      "Epoch 9/10\n",
      "35625/35625 [==============================] - 29s 802us/step - loss: 0.3675 - acc: 0.8787 - val_loss: 0.3888 - val_acc: 0.8649\n",
      "Epoch 10/10\n",
      "35625/35625 [==============================] - 28s 798us/step - loss: 0.3476 - acc: 0.8862 - val_loss: 0.0602 - val_acc: 0.9835\n",
      "Test loss: 0.06019232223366526\n",
      "Test accuracy: 0.9834947368421053\n"
     ]
    }
   ],
   "source": [
    "model_denseloss='categorical_crossentropy'\n",
    "\n",
    "history_dense = model_dense.fit(X_flat_train, Y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, Y_test))\n",
    "score = model_dense.evaluate(X_flat_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy: 0.9834947368421053 on the test set using a neural network with two dense layers (256 nodes and 128 nodes) and dropout = 0.1(to reduce overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A deeper network (5 dense layers (256-128-128-128-128 nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 71)                9159      \n",
      "=================================================================\n",
      "Total params: 1,647,047\n",
      "Trainable params: 1,647,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35625 samples, validate on 35625 samples\n",
      "Epoch 1/10\n",
      "35625/35625 [==============================] - 29s 808us/step - loss: 2.9985 - acc: 0.1828 - val_loss: 1.6192 - val_acc: 0.4512\n",
      "Epoch 2/10\n",
      "35625/35625 [==============================] - 29s 801us/step - loss: 1.4866 - acc: 0.5079 - val_loss: 1.0322 - val_acc: 0.6430\n",
      "Epoch 3/10\n",
      "35625/35625 [==============================] - 28s 797us/step - loss: 0.9747 - acc: 0.6764 - val_loss: 0.4360 - val_acc: 0.8558\n",
      "Epoch 4/10\n",
      "35625/35625 [==============================] - 28s 788us/step - loss: 0.7180 - acc: 0.7581 - val_loss: 0.3211 - val_acc: 0.8883\n",
      "Epoch 5/10\n",
      "35625/35625 [==============================] - 29s 811us/step - loss: 0.5442 - acc: 0.8153 - val_loss: 0.2308 - val_acc: 0.9178\n",
      "Epoch 6/10\n",
      "35625/35625 [==============================] - 29s 810us/step - loss: 0.4456 - acc: 0.8559 - val_loss: 0.3237 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      "35625/35625 [==============================] - 29s 817us/step - loss: 0.3693 - acc: 0.8752 - val_loss: 0.3110 - val_acc: 0.8847\n",
      "Epoch 8/10\n",
      "35625/35625 [==============================] - 28s 799us/step - loss: 0.3218 - acc: 0.8968 - val_loss: 0.0557 - val_acc: 0.9821\n",
      "Epoch 9/10\n",
      "35625/35625 [==============================] - 31s 857us/step - loss: 0.2637 - acc: 0.9133 - val_loss: 0.7523 - val_acc: 0.7926\n",
      "Epoch 10/10\n",
      "35625/35625 [==============================] - 29s 815us/step - loss: 0.2507 - acc: 0.9204 - val_loss: 0.0554 - val_acc: 0.9798\n",
      "Test loss: 0.05540531318712597\n",
      "Test accuracy: 0.9798456140350877\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "# Add dense layers to create a fully connected MLP\n",
    "# Note that we specify an input shape for the first layer, but only the first layer.\n",
    "# Relu is the activation function used\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "# Dropout layers remove features and fight overfitting\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "# End with a number of units equal to the number of classes we have for our outcome\n",
    "model_deep.add(Dense(71, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, Y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, Y_test))\n",
    "score = model_deep.evaluate(X_flat_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35625 samples, validate on 35625 samples\n",
      "Epoch 1/1\n",
      " 6272/35625 [====>.........................] - ETA: 6:26 - loss: 3.9543 - acc: 0.0719"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "# First convolutional layer, note the specification of shape\n",
    "model_cnn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(45, 45, 3)))\n",
    "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Dropout(0.25))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(71, activation='softmax'))\n",
    "\n",
    "model_cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_cnn.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model_cnn.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model_cnn.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
