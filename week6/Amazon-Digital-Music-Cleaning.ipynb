{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dataframe library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('Digital_Music_5.json', lines=True) #read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5555991584</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>5</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>09 12, 2006</td>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5555991584</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>06 3, 2001</td>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5555991584</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>07 14, 2003</td>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>bob turnley</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>1058140800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  5555991584  [3, 3]        5   \n",
       "1  5555991584  [0, 0]        5   \n",
       "2  5555991584  [2, 2]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...  09 12, 2006   \n",
       "1  A clasically-styled and introverted album, Mem...   06 3, 2001   \n",
       "2  I never thought Enya would reach the sublime h...  07 14, 2003   \n",
       "\n",
       "       reviewerID          reviewerName                   summary  \\\n",
       "0  A3EBHHCZO6V2A4  Amaranth \"music fan\"   Enya's last great album   \n",
       "1   AZPWAXJG9OJXV             bethtexas  Enya at her most elegant   \n",
       "2  A38IRL0X2T4DPF           bob turnley           The best so far   \n",
       "\n",
       "   unixReviewTime  \n",
       "0      1158019200  \n",
       "1       991526400  \n",
       "2      1058140800  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                0\n",
       "helpful             0\n",
       "overall             0\n",
       "reviewText          0\n",
       "reviewTime          0\n",
       "reviewerID          0\n",
       "reviewerName      177\n",
       "summary             0\n",
       "unixReviewTime      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64706, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>B000000WBB</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>5</td>\n",
       "      <td>Big Ups to Lil Flip for showing respect to the...</td>\n",
       "      <td>06 11, 2005</td>\n",
       "      <td>A3CY5UH5JR4MJT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Gods Of The South</td>\n",
       "      <td>1118448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>B000001A9C</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>5</td>\n",
       "      <td>Now I know that some of you are disappointed t...</td>\n",
       "      <td>05 17, 2004</td>\n",
       "      <td>A2QT0JAUOAOF2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Diary of a Motown and Soul Music Legend</td>\n",
       "      <td>1084752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>B000001DUK</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I enjoy most forms of Classic Rock - but when ...</td>\n",
       "      <td>04 3, 2014</td>\n",
       "      <td>A1Q6PG0Y3XZL7M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolute Best Country-Blues Rock - Timlessly A...</td>\n",
       "      <td>1396483200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin helpful  overall  \\\n",
       "1967  B000000WBB  [1, 3]        5   \n",
       "3180  B000001A9C  [3, 3]        5   \n",
       "3607  B000001DUK  [0, 0]        5   \n",
       "\n",
       "                                             reviewText   reviewTime  \\\n",
       "1967  Big Ups to Lil Flip for showing respect to the...  06 11, 2005   \n",
       "3180  Now I know that some of you are disappointed t...  05 17, 2004   \n",
       "3607  I enjoy most forms of Classic Rock - but when ...   04 3, 2014   \n",
       "\n",
       "          reviewerID reviewerName  \\\n",
       "1967  A3CY5UH5JR4MJT          NaN   \n",
       "3180   A2QT0JAUOAOF2          NaN   \n",
       "3607  A1Q6PG0Y3XZL7M          NaN   \n",
       "\n",
       "                                                summary  unixReviewTime  \n",
       "1967                              The Gods Of The South      1118448000  \n",
       "3180        The Diary of a Motown and Soul Music Legend      1084752000  \n",
       "3607  Absolute Best Country-Blues Rock - Timlessly A...      1396483200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.reviewerName.isnull()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin              object\n",
       "helpful           object\n",
       "overall            int64\n",
       "reviewText        object\n",
       "reviewTime        object\n",
       "reviewerID        object\n",
       "reviewerName      object\n",
       "summary           object\n",
       "unixReviewTime     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentiment analysis by using Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_word = vectorizer.fit(data.reviewText)\n",
    "bag_of_word = vectorizer.transform(data.reviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print (bag_of_word[0][0,4324])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 790)\t1\n",
      "  (0, 1251)\t1\n",
      "  (0, 4324)\t2\n",
      "  (0, 5878)\t2\n",
      "  (0, 5980)\t1\n",
      "  (0, 6006)\t1\n",
      "  (0, 6398)\t2\n",
      "  (0, 6903)\t1\n",
      "  (0, 7353)\t1\n",
      "  (0, 7414)\t1\n",
      "  (0, 7932)\t1\n",
      "  (0, 8751)\t1\n",
      "  (0, 8821)\t1\n",
      "  (0, 10567)\t1\n",
      "  (0, 11690)\t1\n",
      "  (0, 13467)\t1\n",
      "  (0, 13684)\t1\n",
      "  (0, 14675)\t1\n",
      "  (0, 15063)\t1\n",
      "  (0, 18162)\t1\n",
      "  (0, 18796)\t1\n",
      "  (0, 26220)\t1\n",
      "  (0, 27687)\t1\n",
      "  (0, 27864)\t1\n",
      "  (0, 28345)\t1\n",
      "  :\t:\n",
      "  (64705, 72532)\t3\n",
      "  (64705, 72604)\t2\n",
      "  (64705, 74071)\t1\n",
      "  (64705, 77821)\t1\n",
      "  (64705, 78558)\t4\n",
      "  (64705, 84107)\t3\n",
      "  (64705, 87737)\t4\n",
      "  (64705, 92398)\t1\n",
      "  (64705, 92599)\t1\n",
      "  (64705, 94781)\t1\n",
      "  (64705, 94917)\t2\n",
      "  (64705, 95407)\t3\n",
      "  (64705, 102441)\t2\n",
      "  (64705, 102555)\t5\n",
      "  (64705, 102720)\t1\n",
      "  (64705, 102865)\t1\n",
      "  (64705, 103290)\t1\n",
      "  (64705, 103342)\t1\n",
      "  (64705, 103505)\t1\n",
      "  (64705, 105006)\t1\n",
      "  (64705, 113062)\t1\n",
      "  (64705, 113945)\t2\n",
      "  (64705, 114948)\t1\n",
      "  (64705, 115732)\t3\n",
      "  (64705, 115875)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102555\n"
     ]
    }
   ],
   "source": [
    "print (vectorizer.vocabulary_.get(\"the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các từ trong 2 văn bản là:\n",
      " {'xem', 'Trâm', 'Phúc', 'thích', 'Ngoài', 'ra', 'bơi', 'lội', ',', 'phim', 'cũng', 'còn'}\n",
      "Số từ xuất hiện trong văn bản 1 là:\n",
      " {'xem': 2, 'Trâm': 1, 'Phúc': 1, 'thích': 2, 'Ngoài': 0, 'ra': 0, 'bơi': 0, 'lội': 0, ',': 1, 'phim': 2, 'cũng': 1, 'còn': 0}\n",
      "\n",
      "Số từ xuất hiện trong văn bản 2 là:\n",
      " {'xem': 0, 'Trâm': 0, 'Phúc': 1, 'thích': 1, 'Ngoài': 1, 'ra': 1, 'bơi': 1, 'lội': 1, ',': 1, 'phim': 0, 'cũng': 0, 'còn': 1}\n",
      "\n",
      "Kết quả TF:\n",
      " văn bản 1: {'xem': 0.2, 'Trâm': 0.1, 'Phúc': 0.1, 'thích': 0.2, 'Ngoài': 0.0, 'ra': 0.0, 'bơi': 0.0, 'lội': 0.0, ',': 0.1, 'phim': 0.2, 'cũng': 0.1, 'còn': 0.0}\n",
      " văn bản 2: {'xem': 0.0, 'Trâm': 0.0, 'Phúc': 0.125, 'thích': 0.125, 'Ngoài': 0.125, 'ra': 0.125, 'bơi': 0.125, 'lội': 0.125, ',': 0.125, 'phim': 0.0, 'cũng': 0.0, 'còn': 0.125}\n",
      "Kết Quả IDF:\n",
      " {'xem': 0.6931471805599453, 'Trâm': 0.6931471805599453, 'Phúc': 0.0, 'thích': 0.0, 'Ngoài': 0.6931471805599453, 'ra': 0.6931471805599453, 'bơi': 0.6931471805599453, 'lội': 0.6931471805599453, ',': 0.0, 'phim': 0.6931471805599453, 'cũng': 0.6931471805599453, 'còn': 0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Phúc thích xem phim , Trâm cũng thích xem phim\"\n",
    "text2 = \"Ngoài ra , Phúc còn thích bơi lội\"\n",
    "bowA = text1.split(\" \") # tách từ ở văn bản 1\n",
    "bowB = text2.split(\" \") # tách từ ở văn bản 2\n",
    "#Tạo một dictionary\n",
    "word_dict = set(bowA).union(set(bowB))\n",
    "wordDictA = dict.fromkeys(word_dict, 0)\n",
    "wordDictB = dict.fromkeys(word_dict, 0)\n",
    "\n",
    "#Đếm số lượng từ\n",
    "for word in bowA:\n",
    "    wordDictA[word]+=1\n",
    "for word in bowB:\n",
    "    wordDictB[word]+=1\n",
    "\n",
    "# calculate TF\n",
    "def compute_TF(word_dict, bow):\n",
    "    tf_dict = {}\n",
    "    bow_count = len(bow)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count / float(bow_count)\n",
    "    return tf_dict\n",
    "\n",
    "\n",
    "def compute_IDF(doc_list):\n",
    "    import math #import thư viện math\n",
    "    idf_dict = {} #tạo một dictionary rỗng\n",
    "    N = len(doc_list) #gán độ dài của list cho biến N\n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(), 0) #tạo dictionary lưu các keys với value = 0\n",
    "    #lọc ra thành 1 list gồm các từ xuất hiện >=1 lần\n",
    "    for doc in doc_list:\n",
    "        for word, count in doc.items():\n",
    "            if count > 0:\n",
    "                idf_dict[word] += 1\n",
    "    for word, count in idf_dict.items():\n",
    "        idf_dict[word] = math.log(N / float(count))\n",
    "    return idf_dict\n",
    "print(\"Các từ trong 2 văn bản là:\\n {}\".format(word_dict))\n",
    "print(\"Số từ xuất hiện trong văn bản 1 là:\\n {}\\n\\nSố từ xuất hiện trong văn bản 2 là:\\n {}\".format(wordDictA,wordDictB))\n",
    "print(\"\\nKết quả TF:\\n văn bản 1: {}\\n văn bản 2: {}\".format(compute_TF(wordDictA,bowA),compute_TF(wordDictB,bowB)))\n",
    "print(\"Kết Quả IDF:\\n {}\".format(compute_IDF([wordDictA, wordDictB])))\n",
    "\n",
    "\n",
    "def compute_TFIDF(tf_bow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_bow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf\n",
    "import pandas as pd\n",
    "tf_bowA = compute_TF(wordDictA, bowA)\n",
    "tf_bowB = compute_TF(wordDictB, bowB)\n",
    "idfs=compute_IDF([wordDictA, wordDictB])\n",
    "tfidf_bowA = compute_TFIDF(tf_bowA, idfs)\n",
    "tfidf_bowB = compute_TFIDF(tf_bowB, idfs)\n",
    "df = pd.DataFrame([tfidf_bowA, tfidf_bowB])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>Ngoài</th>\n",
       "      <th>Phúc</th>\n",
       "      <th>Trâm</th>\n",
       "      <th>bơi</th>\n",
       "      <th>còn</th>\n",
       "      <th>cũng</th>\n",
       "      <th>lội</th>\n",
       "      <th>phim</th>\n",
       "      <th>ra</th>\n",
       "      <th>thích</th>\n",
       "      <th>xem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ,     Ngoài  Phúc      Trâm       bơi       còn      cũng       lội  \\\n",
       "0  0.0  0.000000   0.0  0.069315  0.000000  0.000000  0.069315  0.000000   \n",
       "1  0.0  0.086643   0.0  0.000000  0.086643  0.086643  0.000000  0.086643   \n",
       "\n",
       "       phim        ra  thích       xem  \n",
       "0  0.138629  0.000000    0.0  0.138629  \n",
       "1  0.000000  0.086643    0.0  0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
